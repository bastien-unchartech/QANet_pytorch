{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load models.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from config import config\n",
    "\n",
    "D = config.connector_dim\n",
    "Nh = config.num_heads\n",
    "Dword = config.glove_dim\n",
    "Dchar = config.char_dim\n",
    "batch_size = config.batch_size\n",
    "dropout = config.dropout\n",
    "dropout_char = config.dropout_char\n",
    "\n",
    "Dk = D // Nh\n",
    "Dv = D // Nh\n",
    "D_cq_att = D * 4\n",
    "Lc = config.para_limit\n",
    "Lq = config.ques_limit\n",
    "\n",
    "\n",
    "def mask_logits(target, mask):\n",
    "    return target * mask + (1 - mask) * (-1e30)\n",
    "\n",
    "\n",
    "class PosEncoder(nn.Module):\n",
    "    def __init__(self, length):\n",
    "        super().__init__()\n",
    "        freqs = torch.Tensor(\n",
    "            [10000 ** (-i / D) if i % 2 == 0 else -10000 ** ((1 - i) / D) for i in range(D)]).unsqueeze(dim=1)\n",
    "        phases = torch.Tensor([0 if i % 2 == 0 else math.pi / 2 for i in range(D)]).unsqueeze(dim=1)\n",
    "        pos = torch.arange(length).repeat(D, 1)\n",
    "        self.pos_encoding = nn.Parameter(torch.sin(torch.add(torch.mul(pos, freqs), phases)), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pos_encoding\n",
    "        return x\n",
    "\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k, dim=1, bias=True):\n",
    "        super().__init__()\n",
    "        if dim == 1:\n",
    "            self.depthwise_conv = nn.Conv1d(in_channels=in_ch, out_channels=in_ch, kernel_size=k, groups=in_ch,\n",
    "                                            padding=k // 2, bias=bias)\n",
    "            self.pointwise_conv = nn.Conv1d(in_channels=in_ch, out_channels=out_ch, kernel_size=1, padding=0, bias=bias)\n",
    "        elif dim == 2:\n",
    "            self.depthwise_conv = nn.Conv2d(in_channels=in_ch, out_channels=in_ch, kernel_size=k, groups=in_ch,\n",
    "                                            padding=k // 2, bias=bias)\n",
    "            self.pointwise_conv = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=1, padding=0, bias=bias)\n",
    "        else:\n",
    "            raise Exception(\"Wrong dimension for Depthwise Separable Convolution!\")\n",
    "        nn.init.kaiming_normal_(self.depthwise_conv.weight)\n",
    "        nn.init.constant_(self.depthwise_conv.bias, 0.0)\n",
    "        nn.init.kaiming_normal_(self.depthwise_conv.weight)\n",
    "        nn.init.constant_(self.pointwise_conv.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise_conv(self.depthwise_conv(x))\n",
    "\n",
    "\n",
    "class Highway(nn.Module):\n",
    "    def __init__(self, layer_num: int, size: int):\n",
    "        super().__init__()\n",
    "        self.n = layer_num\n",
    "        self.linear = nn.ModuleList([nn.Linear(size, size) for _ in range(self.n)])\n",
    "        self.gate = nn.ModuleList([nn.Linear(size, size) for _ in range(self.n)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        for i in range(self.n):\n",
    "            gate = F.sigmoid(self.gate[i](x))\n",
    "            nonlinear = F.relu(self.linear[i](x))\n",
    "            x = gate * nonlinear + (1 - gate) * x\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        Wo = torch.empty(D, Dv * Nh)\n",
    "        Wqs = [torch.empty(D, Dk) for _ in range(Nh)]\n",
    "        Wks = [torch.empty(D, Dk) for _ in range(Nh)]\n",
    "        Wvs = [torch.empty(D, Dv) for _ in range(Nh)]\n",
    "        nn.init.kaiming_uniform_(Wo)\n",
    "        for i in range(Nh):\n",
    "            nn.init.xavier_uniform_(Wqs[i])\n",
    "            nn.init.xavier_uniform_(Wks[i])\n",
    "            nn.init.xavier_uniform_(Wvs[i])\n",
    "        self.Wo = nn.Parameter(Wo)\n",
    "        self.Wqs = nn.ParameterList([nn.Parameter(X) for X in Wqs])\n",
    "        self.Wks = nn.ParameterList([nn.Parameter(X) for X in Wks])\n",
    "        self.Wvs = nn.ParameterList([nn.Parameter(X) for X in Wvs])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        WQs, WKs, WVs = [], [], []\n",
    "        sqrt_dk_inv = 1 / math.sqrt(Dk)\n",
    "        x = x.transpose(1, 2)\n",
    "        hmask = mask.unsqueeze(1)\n",
    "        vmask = mask.unsqueeze(2)\n",
    "        for i in range(Nh):\n",
    "            WQs.append(torch.matmul(x, self.Wqs[i]))\n",
    "            WKs.append(torch.matmul(x, self.Wks[i]))\n",
    "            WVs.append(torch.matmul(x, self.Wvs[i]))\n",
    "        heads = []\n",
    "        for i in range(Nh):\n",
    "            out = torch.bmm(WQs[i], WKs[i].transpose(1, 2))\n",
    "            out = torch.mul(out, sqrt_dk_inv)\n",
    "            # not sure... I think `dim` should be 2 since it weighted each column of `WVs[i]`\n",
    "            out = mask_logits(out, hmask)\n",
    "            out = F.softmax(out, dim=2) * vmask\n",
    "            headi = torch.bmm(out, WVs[i])\n",
    "            heads.append(headi)\n",
    "        head = torch.cat(heads, dim=2)\n",
    "        out = torch.matmul(head, self.Wo)\n",
    "        return out.transpose(1, 2)\n",
    "\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv2d = DepthwiseSeparableConv(Dchar, Dchar, 5, dim=2)\n",
    "        self.high = Highway(2, Dword+Dchar)\n",
    "\n",
    "    def forward(self, ch_emb, wd_emb):\n",
    "        ch_emb = ch_emb.permute(0, 3, 1, 2)\n",
    "        ch_emb = F.dropout(ch_emb, p=dropout_char, training=self.training)\n",
    "        ch_emb = self.conv2d(ch_emb)\n",
    "        ch_emb = F.relu(ch_emb)\n",
    "        ch_emb, _ = torch.max(ch_emb, dim=3)\n",
    "        ch_emb = ch_emb.squeeze()\n",
    "        wd_emb = F.dropout(wd_emb, p=dropout, training=self.training)\n",
    "        wd_emb = wd_emb.transpose(1, 2)\n",
    "        emb = torch.cat([ch_emb, wd_emb], dim=1)\n",
    "        emb = self.high(emb)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, conv_num: int, ch_num: int, k: int, length: int):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([DepthwiseSeparableConv(ch_num, ch_num, k) for _ in range(conv_num)])\n",
    "        self.self_att = SelfAttention()\n",
    "        self.fc = nn.Linear(ch_num, ch_num, bias=True)\n",
    "        self.pos = PosEncoder(length)\n",
    "        self.normb = nn.LayerNorm([D, length])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm([D, length]) for _ in range(conv_num)])\n",
    "        self.norme = nn.LayerNorm([D, length])\n",
    "        self.L = conv_num\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        out = self.pos(x)\n",
    "        res = out\n",
    "        out = self.normb(out)\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            out = conv(out)\n",
    "            out = F.relu(out)\n",
    "            out = out + res\n",
    "            if (i + 1) % 2 == 0:\n",
    "                p_drop = dropout * (i + 1) / self.L\n",
    "                out = F.dropout(out, p=p_drop, training=self.training)\n",
    "            res = out\n",
    "            out = self.norms[i](out)\n",
    "        out = self.self_att(out, mask)\n",
    "        out = out + res\n",
    "        out = F.dropout(out, p=dropout, training=self.training)\n",
    "        res = out\n",
    "        out = self.norme(out)\n",
    "        out = self.fc(out.transpose(1, 2)).transpose(1, 2)\n",
    "        out = F.relu(out)\n",
    "        out = out + res\n",
    "        out = F.dropout(out, p=dropout, training=self.training)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CQAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        w = torch.empty(D * 3)\n",
    "        lim = 1 / D\n",
    "        nn.init.uniform_(w, -math.sqrt(lim), math.sqrt(lim))\n",
    "        self.w = nn.Parameter(w)\n",
    "\n",
    "    def forward(self, C, Q, cmask, qmask):\n",
    "        ss = []\n",
    "        C = C.transpose(1, 2)\n",
    "        Q = Q.transpose(1, 2)\n",
    "        cmask = cmask.unsqueeze(2)\n",
    "        qmask = qmask.unsqueeze(1)\n",
    "        \n",
    "        shape = (C.size(0), C.size(1), Q.size(1), C.size(2))\n",
    "        Ct = C.unsqueeze(2).expand(shape)\n",
    "        Qt = Q.unsqueeze(1).expand(shape)\n",
    "        CQ = torch.mul(Ct, Qt)\n",
    "        S = torch.cat([Ct, Qt, CQ], dim=3)\n",
    "        S = torch.matmul(S, self.w)\n",
    "        S1 = F.softmax(mask_logits(S, qmask), dim=2)\n",
    "        S2 = F.softmax(mask_logits(S, cmask), dim=1)\n",
    "        A = torch.bmm(S1, Q)\n",
    "        B = torch.bmm(torch.bmm(S1, S2.transpose(1, 2)), C)\n",
    "        out = torch.cat([C, A, torch.mul(C, A), torch.mul(C, B)], dim=2)\n",
    "        out = F.dropout(out, p=dropout, training=self.training)\n",
    "        return out.transpose(1, 2)\n",
    "\n",
    "\n",
    "class Pointer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        w1 = torch.empty(D * 2)\n",
    "        w2 = torch.empty(D * 2)\n",
    "        lim = 3 / (2 * D)\n",
    "        nn.init.uniform_(w1, -math.sqrt(lim), math.sqrt(lim))\n",
    "        nn.init.uniform_(w2, -math.sqrt(lim), math.sqrt(lim))\n",
    "        self.w1 = nn.Parameter(w1)\n",
    "        self.w2 = nn.Parameter(w2)\n",
    "\n",
    "    def forward(self, M1, M2, M3, mask):\n",
    "        X1 = torch.cat([M1, M2], dim=1)\n",
    "        X2 = torch.cat([M1, M3], dim=1)\n",
    "        Y1 = torch.matmul(self.w1, X1)\n",
    "        Y2 = torch.matmul(self.w2, X2)\n",
    "        Y1 = mask_logits(Y1, mask)\n",
    "        Y2 = mask_logits(Y2, mask)\n",
    "        p1 = F.log_softmax(Y1, dim=1)\n",
    "        p2 = F.log_softmax(Y2, dim=1)\n",
    "        return p1, p2\n",
    "\n",
    "\n",
    "class QANet(nn.Module):\n",
    "    def __init__(self, word_mat, char_mat):\n",
    "        super().__init__()\n",
    "        self.char_emb = nn.Embedding.from_pretrained(torch.Tensor(char_mat), freeze=config.pretrained_char)\n",
    "        self.word_emb = nn.Embedding.from_pretrained(torch.Tensor(word_mat))\n",
    "        self.emb = Embedding()\n",
    "        self.context_conv = DepthwiseSeparableConv(Dword+Dchar,D, 5)\n",
    "        self.question_conv = DepthwiseSeparableConv(Dword+Dchar,D, 5)\n",
    "        self.c_emb_enc = EncoderBlock(conv_num=4, ch_num=D, k=7, length=Lc)\n",
    "        self.q_emb_enc = EncoderBlock(conv_num=4, ch_num=D, k=7, length=Lq)\n",
    "        self.cq_att = CQAttention()\n",
    "        self.cq_resizer = DepthwiseSeparableConv(D * 4, D, 5)\n",
    "        enc_blk = EncoderBlock(conv_num=2, ch_num=D, k=5, length=Lc)\n",
    "        self.model_enc_blks = nn.ModuleList([enc_blk] * 7)\n",
    "        self.out = Pointer()\n",
    "\n",
    "    def forward(self, Cwid, Ccid, Qwid, Qcid):\n",
    "        cmask = (torch.zeros_like(Cwid) != Cwid).float()\n",
    "        qmask = (torch.zeros_like(Qwid) != Qwid).float()\n",
    "        Cw, Cc = self.word_emb(Cwid), self.char_emb(Ccid)\n",
    "        Qw, Qc = self.word_emb(Qwid), self.char_emb(Qcid)\n",
    "        C, Q = self.emb(Cc, Cw), self.emb(Qc, Qw)\n",
    "        C = self.context_conv(C)  \n",
    "        Q = self.question_conv(Q)  \n",
    "        Ce = self.c_emb_enc(C, cmask)\n",
    "        Qe = self.q_emb_enc(Q, qmask)\n",
    "        \n",
    "        X = self.cq_att(Ce, Qe, cmask, qmask)\n",
    "        M1 = self.cq_resizer(X)\n",
    "        for enc in self.model_enc_blks: M1 = enc(M1, cmask)\n",
    "        M2 = M1\n",
    "        for enc in self.model_enc_blks: M2 = enc(M2, cmask)\n",
    "        M3 = M2\n",
    "        for enc in self.model_enc_blks: M3 = enc(M3, cmask)\n",
    "        p1, p2 = self.out(M1, M2, M3, cmask)\n",
    "        return p1, p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
