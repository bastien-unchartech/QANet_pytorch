{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load config.py\n",
    "import os\n",
    "import absl.flags as flags\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "'''\n",
    "The content of this file is mostly copied from https://github.com/HKUST-KnowComp/R-Net/blob/master/config.py\n",
    "'''\n",
    "\n",
    "home = os.path.expanduser(\".\")\n",
    "train_file = os.path.join(home, \"data\", \"squad\", \"train-v1.1.json\")\n",
    "dev_file = os.path.join(home, \"data\", \"squad\", \"dev-v1.1.json\")\n",
    "test_file = os.path.join(home, \"data\", \"squad\", \"dev-v1.1.json\")\n",
    "glove_word_file = os.path.join(home, \"data\", \"glove\", \"glove.840B.300d.txt\")\n",
    "\n",
    "target_dir = \"data\"\n",
    "event_dir = \"log\"\n",
    "save_dir = \"model\"\n",
    "answer_dir = \"log\"\n",
    "train_record_file = os.path.join(target_dir, \"train.npz\")\n",
    "dev_record_file = os.path.join(target_dir, \"dev.npz\")\n",
    "test_record_file = os.path.join(target_dir, \"test.npz\")\n",
    "word_emb_file = os.path.join(target_dir, \"word_emb.json\")\n",
    "char_emb_file = os.path.join(target_dir, \"char_emb.json\")\n",
    "train_eval = os.path.join(target_dir, \"train_eval.json\")\n",
    "dev_eval = os.path.join(target_dir, \"dev_eval.json\")\n",
    "test_eval = os.path.join(target_dir, \"test_eval.json\")\n",
    "dev_meta = os.path.join(target_dir, \"dev_meta.json\")\n",
    "test_meta = os.path.join(target_dir, \"test_meta.json\")\n",
    "word2idx_file = os.path.join(target_dir, \"word2idx.json\")\n",
    "char2idx_file = os.path.join(target_dir, \"char2idx.json\")\n",
    "answer_file = os.path.join(answer_dir, \"answer.json\")\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "if not os.path.exists(event_dir):\n",
    "    os.makedirs(event_dir)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(answer_dir):\n",
    "    os.makedirs(answer_dir)\n",
    "\n",
    "flags.DEFINE_string(\"mode\", \"train\", \"train/debug/test\")\n",
    "\n",
    "flags.DEFINE_string(\"target_dir\", target_dir, \"\")\n",
    "flags.DEFINE_string(\"event_dir\", event_dir, \"\")\n",
    "flags.DEFINE_string(\"save_dir\", save_dir, \"\")\n",
    "flags.DEFINE_string(\"train_file\", train_file, \"\")\n",
    "flags.DEFINE_string(\"dev_file\", dev_file, \"\")\n",
    "flags.DEFINE_string(\"test_file\", test_file, \"\")\n",
    "flags.DEFINE_string(\"glove_word_file\", glove_word_file, \"\")\n",
    "\n",
    "flags.DEFINE_string(\"train_record_file\", train_record_file, \"\")\n",
    "flags.DEFINE_string(\"dev_record_file\", dev_record_file, \"\")\n",
    "flags.DEFINE_string(\"test_record_file\", test_record_file, \"\")\n",
    "flags.DEFINE_string(\"word_emb_file\", word_emb_file, \"\")\n",
    "flags.DEFINE_string(\"char_emb_file\", char_emb_file, \"\")\n",
    "flags.DEFINE_string(\"train_eval_file\", train_eval, \"\")\n",
    "flags.DEFINE_string(\"dev_eval_file\", dev_eval, \"\")\n",
    "flags.DEFINE_string(\"test_eval_file\", test_eval, \"\")\n",
    "flags.DEFINE_string(\"dev_meta\", dev_meta, \"\")\n",
    "flags.DEFINE_string(\"test_meta\", test_meta, \"\")\n",
    "flags.DEFINE_string(\"word2idx_file\", word2idx_file, \"\")\n",
    "flags.DEFINE_string(\"char2idx_file\", char2idx_file, \"\")\n",
    "flags.DEFINE_string(\"answer_file\", answer_file, \"\")\n",
    "\n",
    "\n",
    "flags.DEFINE_integer(\"glove_char_size\", 94, \"Corpus size for Glove\")\n",
    "flags.DEFINE_integer(\"glove_word_size\", int(2.2e6), \"Corpus size for Glove\")\n",
    "flags.DEFINE_integer(\"glove_dim\", 300, \"Embedding dimension for Glove\")\n",
    "flags.DEFINE_integer(\"char_dim\", 64, \"Embedding dimension for char\")\n",
    "\n",
    "flags.DEFINE_integer(\"para_limit\", 400, \"Limit length for paragraph\")\n",
    "flags.DEFINE_integer(\"ques_limit\", 50, \"Limit length for question\")\n",
    "flags.DEFINE_integer(\"ans_limit\", 30, \"Limit length for answers\")\n",
    "# flags.DEFINE_integer(\"test_para_limit\", 400, \"Limit length for paragraph in test file\")\n",
    "# flags.DEFINE_integer(\"test_ques_limit\", 100, \"Limit length for question in test file\")\n",
    "flags.DEFINE_integer(\"char_limit\", 16, \"Limit length for character\")\n",
    "flags.DEFINE_integer(\"word_count_limit\", -1, \"Min count for word\")\n",
    "flags.DEFINE_integer(\"char_count_limit\", -1, \"Min count for char\")\n",
    "\n",
    "flags.DEFINE_integer(\"capacity\", 15000, \"Batch size of dataset shuffle\")\n",
    "flags.DEFINE_integer(\"num_threads\", 4, \"Number of threads in input pipeline\")\n",
    "flags.DEFINE_boolean(\"is_bucket\", False, \"build bucket batch iterator or not\")\n",
    "flags.DEFINE_list(\"bucket_range\", [40, 401, 40], \"the range of bucket\")\n",
    "\n",
    "flags.DEFINE_integer(\"batch_size\", 16, \"Batch size\")\n",
    "flags.DEFINE_integer(\"num_steps\", 60000, \"Number of steps\")\n",
    "flags.DEFINE_integer(\"checkpoint\", 1000, \"checkpoint to save and evaluate the model\")\n",
    "flags.DEFINE_integer(\"period\", 100, \"period to save batch loss\")\n",
    "flags.DEFINE_integer(\"val_num_batches\", 150, \"Number of batches to evaluate the model\")\n",
    "flags.DEFINE_integer(\"test_num_batches\", 150, \"Number of batches to evaluate the model\")\n",
    "flags.DEFINE_float(\"dropout\", 0.1, \"Dropout prob across the layers\")\n",
    "flags.DEFINE_float(\"dropout_char\", 0.05, \"Dropout prob across the layers\")\n",
    "flags.DEFINE_float(\"grad_clip\", 5.0, \"Global Norm gradient clipping rate\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate\")\n",
    "flags.DEFINE_integer(\"lr_warm_up_num\", 1000, \"Number of warm-up steps of learning rate\")\n",
    "flags.DEFINE_float(\"ema_decay\", 0.9999, \"Exponential moving average decay\")\n",
    "flags.DEFINE_float(\"beta1\", 0.8, \"Beta 1\")\n",
    "flags.DEFINE_float(\"beta2\", 0.999, \"Beta 2\")\n",
    "# flags.DEFINE_float(\"l2_norm\", 3e-7, \"L2 norm scale\")\n",
    "flags.DEFINE_integer(\"early_stop\", 10, \"Checkpoints for early stop\")\n",
    "flags.DEFINE_integer(\"connector_dim\", 96, \"Dimension of connectors of each layer\")\n",
    "flags.DEFINE_integer(\"num_heads\", 2, \"Number of heads in multi-head attention\")\n",
    "\n",
    "# Extensions (Uncomment corresponding line in download.sh to download the required data)\n",
    "glove_char_file = os.path.join(home, \"data\", \"glove\", \"glove.840B.300d-char.txt\")\n",
    "flags.DEFINE_string(\"glove_char_file\", glove_char_file, \"Glove character embedding\")\n",
    "flags.DEFINE_boolean(\"pretrained_char\", False, \"Whether to use pretrained char embedding\")\n",
    "\n",
    "#fasttext_file = os.path.join(home, \"data\", \"fasttext\", \"wiki-news-300d-1M.vec\")\n",
    "#flags.DEFINE_string(\"fasttext_file\", fasttext_file, \"Fasttext word embedding\")\n",
    "#flags.DEFINE_boolean(\"fasttext\", False, \"Whether to use fasttext\")\n",
    "\n",
    "config = flags.FLAGS\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
