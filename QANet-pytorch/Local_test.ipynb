{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc import *\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import ujson as json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from codecs import open\n",
    "from config import config\n",
    "import sys\n",
    "from absl import app\n",
    "from config import config, device\n",
    "from preproc import preproc\n",
    "from absl import app\n",
    "from math import log2\n",
    "import os\n",
    "import numpy as np\n",
    "import ujson as json\n",
    "import re\n",
    "from collections import Counter\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.cuda\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQuADDataset(Dataset):\n",
    "    def __init__(self, npz_file, num_steps, batch_size):\n",
    "        super().__init__()\n",
    "        data = np.load(npz_file)\n",
    "        self.context_idxs = torch.from_numpy(data[\"context_idxs\"]).long()\n",
    "        self.context_char_idxs = torch.from_numpy(data[\"context_char_idxs\"]).long()\n",
    "        self.ques_idxs = torch.from_numpy(data[\"ques_idxs\"]).long()\n",
    "        self.ques_char_idxs = torch.from_numpy(data[\"ques_char_idxs\"]).long()\n",
    "        self.y1s = torch.from_numpy(data[\"y1s\"]).long()\n",
    "        self.y2s = torch.from_numpy(data[\"y2s\"]).long()\n",
    "        self.ids = torch.from_numpy(data[\"ids\"]).long()\n",
    "        num = len(self.ids)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps if num_steps >= 0 else num // batch_size\n",
    "        num_items = num_steps * batch_size\n",
    "        idxs = list(range(num))\n",
    "        self.idx_map = []\n",
    "        i, j = 0, num\n",
    "\n",
    "        while j <= num_items:\n",
    "            random.shuffle(idxs)\n",
    "            self.idx_map += idxs.copy()\n",
    "            i = j\n",
    "            j += num\n",
    "        random.shuffle(idxs)\n",
    "        self.idx_map += idxs[:num_items - i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_steps\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        idxs = torch.LongTensor(self.idx_map[item:item + self.batch_size])\n",
    "        res = (self.context_idxs[idxs],\n",
    "               self.context_char_idxs[idxs],\n",
    "               self.ques_idxs[idxs],\n",
    "               self.ques_char_idxs[idxs],\n",
    "               self.y1s[idxs],\n",
    "               self.y2s[idxs], self.ids[idxs])\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter, char_counter = Counter(), Counter()\n",
    "train_examples, train_eval = process_file('data/dev-v1.1.json', \"train\", word_counter, char_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config(sys.argv)\n",
    "word_emb_file = config.glove_word_file  \n",
    "char_emb_file = config.glove_char_file if config.pretrained_char else None\n",
    "char_emb_size = config.glove_char_size if config.pretrained_char else None\n",
    "char_emb_dim = config.glove_dim if config.pretrained_char else config.char_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:07<00:00,  6.36it/s]\n",
      "1039it [00:00, 10381.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570 questions in total\n",
      "Generating word embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196018it [03:14, 11277.95it/s]\n",
      "383it [00:00, 3826.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26142 / 28152 tokens have corresponding word embedding vector\n",
      "Generating char embedding...\n",
      "324 tokens have corresponding embedding vector\n",
      "Processing dev examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4597it [00:01, 3718.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5278it [00:01, 3657.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7895it [00:02, 3476.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7331\n",
      "7332\n",
      "7333\n",
      "7334\n",
      "7335\n",
      "7336\n",
      "7337\n",
      "7338\n",
      "7339\n",
      "7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10570it [00:03, 3441.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 10482 / 10570 instances of features in total\n",
      "Saving word embedding...\n",
      "Saving char embedding...\n",
      "Saving train eval...\n",
      "Saving word dictionary...\n",
      "Saving char dictionary...\n",
      "Saving dev meta...\n"
     ]
    }
   ],
   "source": [
    "%run -m main -- --mode data\n",
    "\n",
    "# def main(_):\n",
    "#     from config import config\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/train_eval.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SQuADDataset(config.train_record_file, config.num_steps, config.batch_size)\n",
    "dev_dataset = SQuADDataset(config.dev_record_file, config.test_num_batches, config.batch_size)\n",
    "data = np.load('./data/train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"context_idxs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset.y1s[train_dataset.y2s == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"y1s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_features(config, train_examples, 'train', config.train_record_file,\\\n",
    "               word2idx_dict, char2idx_dict )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
